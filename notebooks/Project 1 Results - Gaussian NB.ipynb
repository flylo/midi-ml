{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from functools import partial\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# from midi_ml.models.linear_decision_rules import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = joblib.load(\"/home/jovyan/persistent_data/data/dumps/labeled_corpus_labels.pkl\")\n",
    "features = joblib.load(\"/home/jovyan/persistent_data/data/dumps/labeled_corpus_matrix.pkl\")\n",
    "features = features.todense()\n",
    "bach_labels = [k for k in range(len(labels)) if labels[k] == \"bach-js\"]\n",
    "mozart_labels = [k for k in range(len(labels)) if labels[k] == \"mozart\"]\n",
    "X = features[bach_labels + mozart_labels].A\n",
    "y = np.array([1 for i in range(len(bach_labels))] + [0 for i in range(len(mozart_labels))])\n",
    "y = y.reshape((y.shape[0],))\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3027, 16384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(object):\n",
    "    \"\"\"\n",
    "    Classifiers of the Naive Bayes family. All input features are assumed to be drawn from\n",
    "     a distribution of the same parametric form\n",
    "     http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 X: np.array,\n",
    "                 y: np.array,\n",
    "                 parametric_form: str = \"multinomial\",\n",
    "                 keep_copy_of_X: bool = True,\n",
    "                 smoothing: int = 1):\n",
    "        \"\"\"\n",
    "        :param X: (N * M)-dimensional array containing the input data in matrix form\n",
    "        :param y: (N * 1)-dimensional array containing the binary target variable, encoded as 0 and 1\n",
    "        :param parametric_form: the parametric form that the features are assumed to take (used to define PDF)\n",
    "        :param keep_copy_of_X: Whether to keep a copy of X in memory (to be used for making predictions on the training set)\n",
    "        :param smoothing: Smoothing parameter for dirichlet prior in multinomial model (sets to None if \"bernoulli\" or \"gaussian\" or chosen)\n",
    "        \"\"\"\n",
    "        parametric_forms = [\"bernoulli\", \"multinomial\", \"gaussian\"]\n",
    "        if parametric_form not in parametric_forms:\n",
    "            raise ValueError(\"Please select a distribution in %s\" % str(parametric_forms))\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes_ = set(self.y)\n",
    "        self.parametric_form_ = parametric_form\n",
    "        self.keep_copy_of_X = keep_copy_of_X\n",
    "        if parametric_form is \"multinomial\":\n",
    "            self.smoothing_ = smoothing\n",
    "        else:\n",
    "            self.smoothing_ = None\n",
    "        self.num_records_ = None  # type: int\n",
    "        self.X_given_class_ = {}\n",
    "        self.thetas_ = {}\n",
    "        self.priors_ = {}\n",
    "        self.log_pdf_given_class_ = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def log_gaussian_pdf(x: float, mu: float, sigma: float) -> np.array:\n",
    "        \"\"\"\n",
    "        Log of the Gaussian probability density function\n",
    "        :param x: value (or np.array of values) at which we compute the relative log-likelihood of drawing that point\n",
    "        :param mu: mean of the Gaussian\n",
    "        :param sigma: standard deviation of the Gaussian\n",
    "        :return: Array with the log-probability of each x\n",
    "        \"\"\"\n",
    "        return np.array(np.log(1. / np.sqrt(2 * np.pi * sigma ** 2)) - (x - mu) ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "    def _get_class_conditional_data(self):\n",
    "        \"\"\"\n",
    "        Separate the data by class\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.num_records_ = self.X.shape[0]\n",
    "        for c in self.classes_:\n",
    "            self.X_given_class_[c] = self.X[np.where(self.y == c)]\n",
    "            self.priors_[c] = float(self.X_given_class_[c].shape[0]) / self.num_records_\n",
    "        if not self.keep_copy_of_X:\n",
    "            self.X = None\n",
    "\n",
    "    def _make_predictions(self, X: np.array = None):\n",
    "        \"\"\"\n",
    "        Predict the class of the input values X\n",
    "        :param X: matrix to make predictions with\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        predictions = np.zeros((X.shape[0], len(self.classes_)))\n",
    "        for c in self.classes_:\n",
    "            if self.parametric_form_ in (\"multinomial\", \"bernoulli\"):\n",
    "                class_conditional_log_probabilities = np.dot(X, self.thetas_[c])\n",
    "            elif self.parametric_form_ == \"gaussian\":\n",
    "                class_conditional_log_probabilities = np.nan_to_num(self.log_pdf_given_class_[c](X)).sum(axis=1)\n",
    "            else:\n",
    "                raise ValueError(\"Must select proper feature family to make predictions\")\n",
    "            # we add the log of the prior probability of the class as an \"intercept\"\n",
    "            predictions[:, c] = class_conditional_log_probabilities + np.log(self.priors_[c])\n",
    "        return predictions.argmax(axis=1)\n",
    "\n",
    "    def predict(self, new_X: np.array = None) -> np.array:\n",
    "        \"\"\"\n",
    "        Exposed API to make predictions\n",
    "        :param new_X: New set of X values to make predictions with (optional)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if new_X is None:\n",
    "            if not self.keep_copy_of_X:\n",
    "                raise ValueError(\"Must keep copy of X in order to make predictions\")\n",
    "            return self._make_predictions(self.X)\n",
    "        else:\n",
    "            return self._make_predictions(new_X)\n",
    "\n",
    "    def _train_bernoulli_model(self):\n",
    "        \"\"\"\n",
    "        Train a Bernoulli Naive Bayes\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # We use the log of the probability that a document is drawn from this parametric\n",
    "        # form of the distribution to ease the computation (by avoiding multiplying very small numbers)\n",
    "        for c in self.classes_:\n",
    "            class_size = self.X_given_class_[c].shape[0]\n",
    "            feature_counts = self.X_given_class_[c].sum(axis=0)\n",
    "            self.thetas_[c] = np.log(feature_counts + 1) - np.log(class_size + 2)\n",
    "\n",
    "    def _train_multinomial_model(self):\n",
    "        \"\"\"\n",
    "        Train a Multinomial Naive Bayes\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # We use the log of the probability that a document is drawn from this parametric\n",
    "        # form of the distribution to ease the computation (by avoiding multiplying very small numbers)\n",
    "        for c in self.classes_:\n",
    "            # get values of n\n",
    "            feature_sums = self.X_given_class_[c].sum(axis=0)\n",
    "            alpha_i = float(self.smoothing_) / self.X_given_class_[c].shape[1]\n",
    "            alpha = self.smoothing_\n",
    "            self.thetas_[c] = np.log(feature_sums + alpha_i) - np.log(feature_sums.sum() + alpha)\n",
    "\n",
    "    # TODO: in high dimensions we'll be storing 10s of thousands of functions which could be inefficient\n",
    "    def _train_gaussian_model(self):\n",
    "        \"\"\"\n",
    "        Train a Gaussain Naive Bayes\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for c in self.classes_:\n",
    "            means = self.X_given_class_[c].mean(axis=0)\n",
    "            variances = self.X_given_class_[c].var(axis=0)\n",
    "            self.log_pdf_given_class_[c] = partial(self.log_gaussian_pdf,\n",
    "                                                   mu=means,\n",
    "                                                   sigma=np.sqrt(variances))\n",
    "\n",
    "    def _get_parametric_probability_estimates(self, parametric_form: str):\n",
    "        \"\"\"\n",
    "        Estimate the parameters of the parametric probability distributions\n",
    "        :param parametric_form: the form we assume for estimating PDFs/PMFs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if parametric_form == \"bernoulli\":\n",
    "            self._train_bernoulli_model()\n",
    "        elif parametric_form == \"multinomial\":\n",
    "            self._train_multinomial_model()\n",
    "        elif parametric_form == \"gaussian\":\n",
    "            self._train_gaussian_model()\n",
    "        else:\n",
    "            raise ValueError(\"Please select a valid family of probability distributions\")\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Exposed API for training model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self._get_class_conditional_data()\n",
    "        self._get_parametric_probability_estimates(parametric_form=self.parametric_form_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:48: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:48: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:48: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "actuals = []\n",
    "nb_models = []\n",
    "i = 0\n",
    "for train_idx, test_idx in KFold(n=X.shape[0], n_folds=5, shuffle=True):\n",
    "    X_train = X[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_train = y[train_idx]\n",
    "    y_test = y[test_idx]\n",
    "    nb = NaiveBayesClassifier(X_train, y_train,\n",
    "                              parametric_form=\"gaussian\", keep_copy_of_X=False)\n",
    "    \n",
    "    nb.fit()\n",
    "    \n",
    "    preds = nb.predict(X_test)\n",
    "    predicted.append(preds)\n",
    "    actuals.append(y_test)\n",
    "    nb_models.append(nb)\n",
    "    pickle.dump(nb_models, open(\"./dumps/gaussian_nb/nb_model_fold_{fold}.pkl\"\n",
    "                                .format(fold=str(i)), 'wb'))\n",
    "    pickle.dump(predicted, open(\"./dumps/gaussian_nb/predicted_fold_{fold}.pkl\"\n",
    "                                .format(fold=str(i)), 'wb'))\n",
    "    pickle.dump(actuals, open(\"./dumps/gaussian_nb/actuals_fold_{fold}.pkl\"\n",
    "                                .format(fold=str(i)), 'wb'))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predicted_fold_0.pkl',\n",
       " 'actuals_fold_2.pkl',\n",
       " 'predicted_fold_1.pkl',\n",
       " 'nb_model_fold_1.pkl',\n",
       " 'actuals_fold_4.pkl',\n",
       " 'predicted_fold_3.pkl',\n",
       " 'predicted_fold_4.pkl',\n",
       " 'predicted_fold_2.pkl',\n",
       " 'actuals_fold_0.pkl',\n",
       " 'nb_model_fold_2.pkl',\n",
       " 'nb_model_fold_4.pkl',\n",
       " 'actuals_fold_3.pkl',\n",
       " 'nb_model_fold_3.pkl',\n",
       " 'actuals_fold_1.pkl',\n",
       " 'nb_model_fold_0.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder = \"./dumps/gaussian_nb/\"\n",
    "os.listdir(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pickle.load(open(model_folder + \"predicted_fold_4.pkl\", 'rb'))\n",
    "actuals = pickle.load(open(model_folder + \"actuals_fold_4.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[ 41  87]\n",
      " [ 19 459]]\n",
      "\taccuracy\n",
      "\t\t 0.825082508251\n",
      "\tf1\n",
      "\t\t 0.896484375\n",
      "\trecall\n",
      "\t\t 0.960251046025\n",
      "\tprecision\n",
      "\t\t 0.840659340659\n",
      "confusion matrix\n",
      "[[ 47  96]\n",
      " [ 18 445]]\n",
      "\taccuracy\n",
      "\t\t 0.811881188119\n",
      "\tf1\n",
      "\t\t 0.886454183267\n",
      "\trecall\n",
      "\t\t 0.961123110151\n",
      "\tprecision\n",
      "\t\t 0.822550831793\n",
      "confusion matrix\n",
      "[[ 37 105]\n",
      " [  9 454]]\n",
      "\taccuracy\n",
      "\t\t 0.811570247934\n",
      "\tf1\n",
      "\t\t 0.888454011742\n",
      "\trecall\n",
      "\t\t 0.980561555076\n",
      "\tprecision\n",
      "\t\t 0.812164579606\n",
      "confusion matrix\n",
      "[[ 50 108]\n",
      " [ 13 434]]\n",
      "\taccuracy\n",
      "\t\t 0.8\n",
      "\tf1\n",
      "\t\t 0.877654196158\n",
      "\trecall\n",
      "\t\t 0.970917225951\n",
      "\tprecision\n",
      "\t\t 0.80073800738\n",
      "confusion matrix\n",
      "[[ 45  95]\n",
      " [ 27 438]]\n",
      "\taccuracy\n",
      "\t\t 0.798347107438\n",
      "\tf1\n",
      "\t\t 0.877755511022\n",
      "\trecall\n",
      "\t\t 0.941935483871\n",
      "\tprecision\n",
      "\t\t 0.821763602251\n"
     ]
    }
   ],
   "source": [
    "for pred, actual in zip(predicted, actuals):\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(actual, pred))\n",
    "    print(\"\\taccuracy\")\n",
    "    print(\"\\t\\t\", accuracy_score(actual, pred))\n",
    "    print(\"\\tf1\")\n",
    "    print(\"\\t\\t\", f1_score(actual, pred))\n",
    "    print(\"\\trecall\")\n",
    "    print(\"\\t\\t\", recall_score(actual, pred))\n",
    "    print(\"\\tprecision\")\n",
    "    print(\"\\t\\t\", precision_score(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[ 41  87]\n",
      " [ 19 459]]\n",
      "\taccuracy\n",
      "\t\t 0.825082508251\n",
      "\tf1\n",
      "\t\t 0.896484375\n",
      "\trecall\n",
      "\t\t 0.960251046025\n",
      "\tprecision\n",
      "\t\t 0.840659340659\n",
      "\tmcc\n",
      "\t\t 0.383423059696\n",
      "confusion matrix\n",
      "[[ 47  96]\n",
      " [ 18 445]]\n",
      "\taccuracy\n",
      "\t\t 0.811881188119\n",
      "\tf1\n",
      "\t\t 0.886454183267\n",
      "\trecall\n",
      "\t\t 0.961123110151\n",
      "\tprecision\n",
      "\t\t 0.822550831793\n",
      "\tmcc\n",
      "\t\t 0.397642916482\n",
      "confusion matrix\n",
      "[[ 37 105]\n",
      " [  9 454]]\n",
      "\taccuracy\n",
      "\t\t 0.811570247934\n",
      "\tf1\n",
      "\t\t 0.888454011742\n",
      "\trecall\n",
      "\t\t 0.980561555076\n",
      "\tprecision\n",
      "\t\t 0.812164579606\n",
      "\tmcc\n",
      "\t\t 0.38556000048\n",
      "confusion matrix\n",
      "[[ 50 108]\n",
      " [ 13 434]]\n",
      "\taccuracy\n",
      "\t\t 0.8\n",
      "\tf1\n",
      "\t\t 0.877654196158\n",
      "\trecall\n",
      "\t\t 0.970917225951\n",
      "\tprecision\n",
      "\t\t 0.80073800738\n",
      "\tmcc\n",
      "\t\t 0.413293172757\n",
      "confusion matrix\n",
      "[[ 45  95]\n",
      " [ 27 438]]\n",
      "\taccuracy\n",
      "\t\t 0.798347107438\n",
      "\tf1\n",
      "\t\t 0.877755511022\n",
      "\trecall\n",
      "\t\t 0.941935483871\n",
      "\tprecision\n",
      "\t\t 0.821763602251\n",
      "\tmcc\n",
      "\t\t 0.343018183263\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "mcc = []\n",
    "predicted = pickle.load(open(model_folder + \"predicted_fold_4.pkl\", 'rb'))\n",
    "actuals = pickle.load(open(model_folder + \"actuals_fold_4.pkl\", 'rb'))\n",
    "for pred, actual in zip(predicted, actuals):\n",
    "    print(\"confusion matrix\")\n",
    "    print(confusion_matrix(actual, pred))\n",
    "    print(\"\\taccuracy\")\n",
    "    acc = accuracy_score(actual, pred)\n",
    "    accuracy.append(acc)\n",
    "    print(\"\\t\\t\", acc)\n",
    "    print(\"\\tf1\")\n",
    "    f = f1_score(actual, pred)\n",
    "    f1.append(f)\n",
    "    print(\"\\t\\t\", f)\n",
    "    print(\"\\trecall\")\n",
    "    r = recall_score(actual, pred)\n",
    "    recall.append(r)\n",
    "    print(\"\\t\\t\", r)\n",
    "    print(\"\\tprecision\")\n",
    "    p = precision_score(actual, pred)\n",
    "    precision.append(p)\n",
    "    print(\"\\t\\t\", p)\n",
    "    print(\"\\tmcc\")\n",
    "    m = matthews_corrcoef(actual, pred)\n",
    "    mcc.append(m)\n",
    "    print(\"\\t\\t\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80937621034830765"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343018183263\n",
      "0.384587466536\n",
      "0.413293172757\n"
     ]
    }
   ],
   "source": [
    "print(np.min(mcc))\n",
    "print(np.mean(mcc))\n",
    "print(np.max(mcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798347107438\n",
      "0.809376210348\n",
      "0.825082508251\n"
     ]
    }
   ],
   "source": [
    "print(np.min(accuracy))\n",
    "print(np.mean(accuracy))\n",
    "print(np.max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
